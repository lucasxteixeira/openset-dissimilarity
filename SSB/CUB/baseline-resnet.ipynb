{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ed8042-d167-460e-bcb1-ccd9e3f11dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import skimage\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "%run ../metric_dissimilarity.py\n",
    "\n",
    "seed = 1234\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39f2162-20de-4a8c-b3fe-a103d48493f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image metadata\n",
    "images = []\n",
    "with open(\"data/images.txt\", \"r\") as f:\n",
    "  for line in f:\n",
    "    img_id, img_file = line.strip().split(\" \")\n",
    "    images.append((img_id, img_file))\n",
    "\n",
    "# Load classes\n",
    "classes = {}\n",
    "with open(\"data/classes.txt\", \"r\") as f:\n",
    "  for line in f:\n",
    "    cls_id, cls_name = line.strip().split(\" \")\n",
    "    classes[cls_name] = cls_id\n",
    "\n",
    "# Load train/test split\n",
    "train_test_split = {}\n",
    "with open(\"data/train_test_split.txt\", \"r\") as f:\n",
    "  for line in f:\n",
    "    img_id, is_train = line.strip().split(\" \")\n",
    "    train_test_split[img_id] = int(is_train)\n",
    "\n",
    "# Load images\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "for (img_id, img_file) in images:\n",
    "  img = skimage.io.imread(f\"data/processed/{img_id}.jpg\")\n",
    "  cls_id = int(classes[img_file.split(\"/\")[0]]) - 1\n",
    "  if train_test_split[img_id] == 1:\n",
    "    X_train.append(img)\n",
    "    Y_train.append(cls_id)\n",
    "  else:\n",
    "    X_test.append(img)\n",
    "    Y_test.append(cls_id)\n",
    "\n",
    "# Convert to numpy\n",
    "X_train = np.array(X_train, dtype=np.uint8)\n",
    "Y_train = np.array(Y_train, dtype=np.int64)\n",
    "\n",
    "X_test = np.array(X_test, dtype=np.uint8)\n",
    "Y_test = np.array(Y_test, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b06a7c-8d9e-4744-87e0-5b4fed130803",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/cub_osr_splits.pkl\", \"rb\") as f:\n",
    "  open_set = pickle.load(f)\n",
    "\n",
    "# Create the open set train set\n",
    "train_known_indices = np.isin(Y_train, open_set[\"known_classes\"])\n",
    "X_train_known = X_train[train_known_indices]\n",
    "Y_train_known = Y_train[train_known_indices]\n",
    "\n",
    "test_known_indices = np.isin(Y_test, open_set[\"known_classes\"])\n",
    "test_unknown_indices = ~test_known_indices\n",
    "\n",
    "test_easy_indices = np.isin(Y_test, open_set[\"unknown_classes\"][\"Easy\"])\n",
    "test_hard_indices = np.isin(Y_test, open_set[\"unknown_classes\"][\"Hard\"] + open_set[\"unknown_classes\"][\"Medium\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7613b103-14f2-41da-9b5b-a4279b5261a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some images and their corresponding labels.\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i in range(30):\n",
    "  ax = plt.subplot(3, 10, i + 1)\n",
    "  plt.imshow(X_train[i] / 255.)\n",
    "  plt.title(Y_train[i])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea9bdcb-80e3-4523-8cee-810153c1fd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, images, labels, augment=True):\n",
    "    self.images = images\n",
    "    self.labels = labels\n",
    "    self.augment = augment\n",
    "\n",
    "    self.transform = A.Compose([\n",
    "      A.RandomCrop(200, 200),\n",
    "      A.VerticalFlip(),\n",
    "      A.HorizontalFlip(),\n",
    "      A.Rotate(),\n",
    "      A.GaussianBlur(),\n",
    "      A.RandomBrightnessContrast(),\n",
    "      ToTensorV2()\n",
    "    ])\n",
    "\n",
    "  def __len__(self):\n",
    "     return len(self.images)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    image = self.images[idx]\n",
    "    label = self.labels[idx]\n",
    "\n",
    "    if self.augment:\n",
    "      image = self.transform(image=image)[\"image\"]\n",
    "    else:\n",
    "      image = ToTensorV2()(image=image)[\"image\"]\n",
    "\n",
    "    image = image / 255.\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6153139c-c131-4b7f-adf4-5350b2dde7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset(X_train, Y_train)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(8):\n",
    "  ax = plt.subplot(3, 4, i + 1)\n",
    "  plt.imshow(np.transpose(images[i].numpy(), (1, 2, 0)))\n",
    "  plt.title(labels[i].numpy())\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebc0622-e5fc-451b-a0f8-1365fe995689",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "  def __init__(self, n_classes):\n",
    "    super(Model, self).__init__()\n",
    "\n",
    "    # Load EfficientNetV2-S as the shared network\n",
    "    self.network = torchvision.models.get_model(\"resnet50\", weights=\"DEFAULT\")\n",
    "\n",
    "    # Freeze the base network\n",
    "    for param in self.network.parameters():\n",
    "      param.requires_grad = False\n",
    "\n",
    "    # Replace the last classification layer with a set of custom layers\n",
    "    self.network.fc = torch.nn.Sequential(\n",
    "      torch.nn.Linear(self.network.fc.in_features, 512),\n",
    "      torch.nn.ReLU(),\n",
    "      torch.nn.Dropout(p=0.2),\n",
    "      torch.nn.Linear(512, 256),\n",
    "      torch.nn.ReLU(),\n",
    "      torch.nn.Dropout(p=0.2),\n",
    "      torch.nn.Linear(256, n_classes)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Pass the input through the shared network\n",
    "    x = self.network(x)\n",
    "    return x\n",
    "\n",
    "  def freeze_network(self):\n",
    "    for param in self.network.parameters():\n",
    "      param.requires_grad = False\n",
    "\n",
    "  def unfreeze_network(self):\n",
    "    for param in self.network.parameters():\n",
    "      param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732100ca-8aea-487e-8f16-315b6e6c72e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, Y, model_id, batch_size=32, epochs=600):\n",
    "\n",
    "  # Define the model filename based on model_id\n",
    "  model_filename = f\"models/baseline-{model_id}.pth\"\n",
    "  print(model_filename)\n",
    "\n",
    "  # Define computation device\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "  # Recode the output since some classes might have been removed\n",
    "  Y = sklearn.preprocessing.LabelEncoder().fit_transform(Y)\n",
    "\n",
    "  # Initialize model and optimizer\n",
    "  n_classes = len(np.unique(Y))\n",
    "  model = None\n",
    "\n",
    "  # Load pre-trained model if exists\n",
    "  if os.path.isfile(model_filename):\n",
    "    model = Model(n_classes)\n",
    "    model.load_state_dict(torch.load(model_filename, weights_only=True))\n",
    "    model.to(device)\n",
    "\n",
    "  # Train a new model if not loaded\n",
    "  if model is None:\n",
    "\n",
    "    dataset = ImageDataset(X, Y)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = Model(n_classes)\n",
    "    model.to(device)\n",
    "\n",
    "    # Initialize loss, optimizer, and training mode\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    model.train()\n",
    "\n",
    "    # Warmup top layers\n",
    "    epoch_loss = 0\n",
    "    for epoch in range(20):\n",
    "      for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "      # Compute average epoch loss\n",
    "      print(f\"Epoch {epoch + 1}, Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "      epoch_loss = 0\n",
    "\n",
    "    # Unfreeze the network\n",
    "    model.unfreeze_network()\n",
    "\n",
    "    # Loss\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Add a learning rate scheduler with linear warmup\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    lr_scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.0001, total_iters=20)\n",
    "    cosine_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=(epochs // 3))\n",
    "    scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[lr_scheduler, cosine_scheduler], milestones=[20])\n",
    "\n",
    "    # Train\n",
    "    epoch_loss = 0\n",
    "    for epoch in range(epochs):\n",
    "      for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "      # Step scheduler\n",
    "      scheduler.step()\n",
    "\n",
    "      # Compute average epoch loss\n",
    "      print(f\"Epoch {epoch + 1}, Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "      epoch_loss = 0\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), model_filename)\n",
    "\n",
    "  # Freeze the model parameters\n",
    "  for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "  # Set to evaluation mode\n",
    "  model.eval()\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78950634-25fc-449e-bd2b-a7042155fc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = train_model(X_train_known, Y_train_known, \"resnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da7796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make predictions\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset = ImageDataset(X_test, Y_test, augment = False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "logits = []\n",
    "with torch.no_grad():\n",
    "  for images, _ in test_loader:\n",
    "    images = images.to(device)\n",
    "    logits.append(model(images).cpu())\n",
    "\n",
    "# Concatenate logits\n",
    "logits = torch.cat(logits, dim=0)\n",
    "probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "# Convert back to numpy\n",
    "logits = logits.numpy()\n",
    "probs = probs.numpy()\n",
    "preds = preds.numpy()\n",
    "\n",
    "# Map the predictions to the known classes\n",
    "known_classes = np.unique(Y_train_known)\n",
    "preds = known_classes[preds]\n",
    "\n",
    "# Closed-set accuracy\n",
    "closed_acc = closed_accuracy(preds, Y_test, test_known_indices)\n",
    "\n",
    "# Open-set scores\n",
    "msp = compute_msp(probs)\n",
    "mls = compute_mls(logits)\n",
    "\n",
    "# AUROC\n",
    "msp_easy_auroc = open_auroc(-msp, test_known_indices, test_easy_indices)\n",
    "mls_easy_auroc = open_auroc(-mls, test_known_indices, test_easy_indices)\n",
    "msp_hard_auroc = open_auroc(-msp, test_known_indices, test_hard_indices)\n",
    "mls_hard_auroc = open_auroc(-mls, test_known_indices, test_hard_indices)\n",
    "\n",
    "msp_easy_openauc = openauc(-msp, preds, Y_test, test_known_indices, test_easy_indices)\n",
    "mls_easy_openauc = openauc(-mls, preds, Y_test, test_known_indices, test_easy_indices)\n",
    "msp_hard_openauc = openauc(-msp, preds, Y_test, test_known_indices, test_hard_indices)\n",
    "mls_hard_openauc = openauc(-mls, preds, Y_test, test_known_indices, test_hard_indices)\n",
    "\n",
    "# Print results\n",
    "pct  = lambda x: f\"{x*100:.1f}%\"\n",
    "fmt  = lambda x: f\"{x*100:.1f}\"\n",
    "pair = lambda a, b: f\"{fmt(a)}/{fmt(b)}\"\n",
    "\n",
    "closed = pct(closed_acc)\n",
    "\n",
    "rows = [\n",
    "  (\"MSP\", closed, pair(msp_easy_auroc, msp_hard_auroc), pair(msp_easy_openauc, msp_hard_openauc)),\n",
    "  (\"MLS\", closed, pair(mls_easy_auroc, mls_hard_auroc), pair(mls_easy_openauc, mls_hard_openauc)),\n",
    "]\n",
    "\n",
    "print(f\"{'':<8}{'Closed':>10}{'AUROC E/H':>12}{'OpAUC E/H':>12}\")\n",
    "print(\"-\"*46)\n",
    "for method, cl, au, op in rows:\n",
    "  print(f\"{method:<8}{cl:>10}{au:>12}{op:>12}\")\n",
    "\n",
    "# CSV\n",
    "print(f\"CUB,All,Holdout,ResNet50,Baseline,,Acck,,{closed_acc}\")\n",
    "print(f\"CUB,All,Holdout,ResNet50,Baseline,MSP,AUROC,Easy,{msp_easy_auroc}\")\n",
    "print(f\"CUB,All,Holdout,ResNet50,Baseline,MSP,AUROC,Hard,{msp_hard_auroc}\")\n",
    "print(f\"CUB,All,Holdout,ResNet50,Baseline,MLS,AUROC,Easy,{mls_easy_auroc}\")\n",
    "print(f\"CUB,All,Holdout,ResNet50,Baseline,MLS,AUROC,Hard,{mls_hard_auroc}\") \n",
    "print(f\"CUB,All,Holdout,ResNet50,Baseline,MSP,OpAUC,Easy,{msp_easy_openauc}\")\n",
    "print(f\"CUB,All,Holdout,ResNet50,Baseline,MSP,OpAUC,Hard,{msp_hard_openauc}\")\n",
    "print(f\"CUB,All,Holdout,ResNet50,Baseline,MLS,OpAUC,Easy,{mls_easy_openauc}\")\n",
    "print(f\"CUB,All,Holdout,ResNet50,Baseline,MLS,OpAUC,Hard,{mls_hard_openauc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
